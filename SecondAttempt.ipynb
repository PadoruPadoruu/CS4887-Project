{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFwqVBE_3CGZ"
   },
   "source": [
    "Name : KEUNG Yat LONG\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n",
    "\n",
    "SID : 5714 6792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85FGcnIy3w58"
   },
   "source": [
    "#Background\n",
    "___\n",
    "- Image generation techniques have existed for decades.\n",
    "- Recent deep learning advances (GANs, diffusion models) have boosted photorealism in AI-generated content (AIGC).\n",
    "- While these advancements have entertainment value, they also pose risks of weaponization.\n",
    "- Detecting AIGC is now a critical issue and a prominent research focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MebXnVvg6bP7"
   },
   "source": [
    "#Basic Information\n",
    "---\n",
    "- **Main task**: Binary classification (detect whether an image is AI-generated or not).\n",
    "- **Input**: RGB images.\n",
    "- **Output**: Binary label indicating if the image is AI-generated.\n",
    "- **Training set**: 45,000 images.\n",
    "- **Validation set**: 5,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSQscqPt5w1n"
   },
   "source": [
    "#Dataset Exploration\n",
    "---\n",
    "- Dataset includes both photographic and AI-generated images.\n",
    "- Photographic images are sourced from ImageNet with varying sizes.\n",
    "- AI-generated images are 512 × 512 × 3, created using Stable Diffusion v1.4, trained on the LAION dataset.\n",
    "- Photographic and AI-generated images have similar semantic content to avoid content bias.\n",
    "- Only binary labels are available for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO8GCV7B8nJw"
   },
   "source": [
    "##Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qK58bk2E9-3N",
    "outputId": "281df9d6-7d29-4f7c-90a1-2e2b2c19c3d4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2seNI4j2i3w",
    "outputId": "ac56d68e-6726-4266-8890-add4eb3db5ca"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# zip_file_path = '/content/drive/MyDrive/CS4487/CS4487 Project/AIGC-Detection-Dataset.zip'\n",
    "\n",
    "# # Create a directory to extract the dataset\n",
    "# output_dir = 'AIGC_Dataset'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Extract the zip file\n",
    "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(output_dir)\n",
    "\n",
    "# print(f'Dataset extracted to {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtO_emP78u3W"
   },
   "source": [
    "##Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yhdG3qhh8zFc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4N9hHliLFv3"
   },
   "source": [
    "Define transformations for training data (with augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AXfJAWV4QASD"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize to 512x512\n",
    "    transforms.RandomRotation(20),  # Random rotation between 0-20 degrees\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomAffine(0, translate=(0.2, 0.2), shear=20),  # Random horizontal and vertical shifts, shear\n",
    "    transforms.RandomResizedCrop(512, scale=(0.8, 1.2)),  # Random zoom\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize([0.4778, 0.4559, 0.4175], [0.2794, 0.2739, 0.2902])  # Normalize using ImageNet's mean and std\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QU0dT-ZOmWT"
   },
   "source": [
    "Define transformations for validation data (no augmentation, only resizing and normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fu4vMUOxQDgL"
   },
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize all validation images to 512x512\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4778, 0.4559, 0.4175], [0.2794, 0.2739, 0.2902])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZKWopX2QUEj"
   },
   "source": [
    "Load the datasets with the ImageFolder utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HkddNjC_EmCO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Split the Training Dataset into Train and Dev Subsets\n",
    "train_dataset = datasets.ImageFolder('AIGC_Dataset/AIGC-Detection-Dataset/train', transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(f'AIGC_Dataset/AIGC-Detection-Dataset/val', transform=val_transforms)\n",
    "\n",
    "def random_split(dataset, lengths):\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    return [torch.utils.data.Subset(dataset, indices[offset - length:offset]) for offset, length in zip(torch._utils._accumulate(lengths), lengths)]\n",
    "# Split training dataset into train and dev subsets\n",
    "train_size = int(0.9 * len(train_dataset))  # 90% training\n",
    "dev_size = len(train_dataset) - train_size  # 10% development\n",
    "train_subset, dev_subset = random_split(train_dataset, [train_size, dev_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qiDzclas3eyC"
   },
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dev_loader = DataLoader(dev_subset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w78VTyITS4AT"
   },
   "source": [
    "##Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eIRKpmPo9Joq"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress bar library\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, train_loader, dev_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, patience=5, device='cuda'):\n",
    "    model.to(device)\n",
    "    best_val_loss = np.inf\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        # Progress bar for training phase\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "        \n",
    "        # Training Phase\n",
    "        for inputs, labels in train_loader_tqdm:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds = (outputs > 0).float()  # Binary threshold\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Update progress bar with current loss\n",
    "            train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        # Validation Phase on Dev Subset\n",
    "        print(\"Evaluating on Dev Set...\")\n",
    "        dev_loss, dev_acc = evaluate_model_with_progress(model, dev_loader, criterion, device)\n",
    "        print(f\"Dev Loss: {dev_loss:.4f}, Dev Accuracy: {dev_acc:.4f}\")\n",
    "\n",
    "        # Adjust learning rate based on validation loss\n",
    "        scheduler.step(dev_loss)\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if dev_loss < best_val_loss:\n",
    "            best_val_loss = dev_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict()  # Save best model\n",
    "            print(\"Validation loss improved. Saving model...\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement for {epochs_without_improvement} epochs.\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "            break\n",
    "\n",
    "    # Restore the best model state\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Final Test on the Validation Set\n",
    "    print(\"Evaluating on Test Set...\")\n",
    "    val_loss, val_acc = evaluate_model_with_progress(model, val_loader, criterion, device)\n",
    "    print(f\"Final Test Loss: {val_loss:.4f}, Test Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Evaluation with progress bar\n",
    "def evaluate_model_with_progress(model, loader, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loader_tqdm = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "        for inputs, labels in loader_tqdm:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            preds = (outputs > 0.5).float()  # Binary threshold\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Update progress bar with current loss\n",
    "            loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    loss = running_loss / len(loader)\n",
    "    acc = correct / total\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLBW25OWTd2l"
   },
   "source": [
    "#Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RgNVPTiX9ME4"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion, device='cuda'):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i, (inputs, labels) in enumerate(loader):\n",
    "            # Print progress every 10 batches\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Processing batch {i + 1}/{len(loader)}\")\n",
    "\n",
    "            # Move data to the specified device\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Handle tuple outputs (e.g., InceptionV3)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            # Apply sigmoid if model outputs raw logits\n",
    "            outputs = torch.sigmoid(outputs).squeeze(1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Compute predictions and update metrics\n",
    "            preds = (outputs > 0.5).float()  # Binary threshold\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    val_loss = running_loss / len(loader)\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvIHEFUG82PK"
   },
   "source": [
    "##Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Un1-I9FTRWkB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "46GZN3XYTbTf"
   },
   "outputs": [],
   "source": [
    "# Save the model to a specified path\n",
    "def save_model(model, model_name):\n",
    "    save_path = f\"{model_name}_model.pth\"  # Save each model with a unique name\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"{model_name} model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P06G7rfWNR7F"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVpAnmfXUh74"
   },
   "source": [
    "DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcAvb_flUjr3",
    "outputId": "b422c75b-3bd3-46a9-f79d-047b665d510b"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from collections import Counter\n",
    "\n",
    "# Build DenseNet121 Model\n",
    "def build_densenet_model():\n",
    "    base_model = models.densenet121(weights='IMAGENET1K_V1')  # Load pretrained DenseNet121\n",
    "    num_features = base_model.classifier.in_features\n",
    "    base_model.classifier = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),  # Dropout for regularization\n",
    "        nn.Linear(512, 1)\n",
    "    )\n",
    "    return base_model\n",
    "\n",
    "# Unfreeze specific layers\n",
    "def unfreeze_layers(model, unfreeze_layer_names):\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in unfreeze_layer_names):\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Calculate class imbalance\n",
    "def compute_class_weights(dataset):\n",
    "    class_counts = Counter(dataset.dataset.targets if hasattr(dataset, 'dataset') else dataset.targets)\n",
    "    class_0 = class_counts[0]\n",
    "    class_1 = class_counts[1]\n",
    "    pos_weight = class_0 / class_1\n",
    "    return torch.tensor([pos_weight]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj1UyU4Z39By"
   },
   "outputs": [],
   "source": [
    "# Initialize DenseNet121 Model\n",
    "densenet_model = build_densenet_model()\n",
    "\n",
    "# Unfreeze layers\n",
    "unfreeze_layers(densenet_model, [\"denseblock4\", \"transition3\"])\n",
    "\n",
    "# Define optimizer with layer-wise learning rates\n",
    "optimizer = optim.Adam([\n",
    "    {'params': densenet_model.features.parameters(), 'lr': 1e-4},  # Fine-tune base\n",
    "    {'params': densenet_model.classifier.parameters(), 'lr': 1e-3}  # Train head\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "# Define scheduler for dynamic learning rate adjustment\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "# Compute class weights for BCEWithLogitsLoss\n",
    "pos_weight = compute_class_weights(train_subset)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJd3SAWp5bEo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1266 [26:16<28:50:47, 83.28s/it, loss=0.44] "
     ]
    }
   ],
   "source": [
    "# Call the training function\n",
    "train_model(\n",
    "    densenet_model,\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=50,\n",
    "    patience=5,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "save_model(densenet_model, \"DenseNet121\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V9Op7Mb4svk"
   },
   "source": [
    "## Show Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdywUef74sjD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to evaluate model and compute metrics\n",
    "def evaluate_metrics(model, loader, device='cuda'):\n",
    "    model.eval()\n",
    "    y_true = []  # Ground truth labels\n",
    "    y_scores = []  # Predicted probabilities\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.cpu().numpy()\n",
    "            outputs = model(inputs).squeeze(1).cpu().numpy()  # Get logits\n",
    "\n",
    "            # Append labels and sigmoid-transformed outputs\n",
    "            y_true.extend(labels)\n",
    "            y_scores.extend(outputs)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_scores = np.array(y_scores)\n",
    "\n",
    "    # Predictions based on threshold\n",
    "    y_preds = (y_scores > 0).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_true, y_preds, target_names=[\"Class 0 (Real)\", \"Class 1 (Fake)\"])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # F1 Score, Recall, and Precision\n",
    "    f1 = (2 * cm[1, 1]) / (2 * cm[1, 1] + cm[1, 0] + cm[0, 1])\n",
    "    recall = cm[1, 1] / (cm[1, 1] + cm[1, 0])\n",
    "    precision = cm[1, 1] / (cm[1, 1] + cm[0, 1])\n",
    "    print(f\"\\nF1 Score: {f1:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "    # ROC AUC Score\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Diagonal line\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix Heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Real\", \"Fake\"], yticklabels=[\"Real\", \"Fake\"])\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your model and validation loader\n",
    "evaluate_metrics(densenet_model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgW2yfvkBJKB"
   },
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HwOAxuXBKvm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9b0c-9kBMW_"
   },
   "outputs": [],
   "source": [
    "# Define a custom dataset loader for binary classification\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        real_dir = os.path.join(data_dir, '0_real')\n",
    "        fake_dir = os.path.join(data_dir, '1_fake')\n",
    "\n",
    "        # Load file paths and labels\n",
    "        self.image_paths = [os.path.join(real_dir, f) for f in os.listdir(real_dir)] + \\\n",
    "                           [os.path.join(fake_dir, f) for f in os.listdir(fake_dir)]\n",
    "        self.labels = [0] * len(os.listdir(real_dir)) + [1] * len(os.listdir(fake_dir))\n",
    "\n",
    "        # Image transformations\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4778, 0.4559, 0.4175], [0.2794, 0.2739, 0.2902])  # Normalize using ImageNet's mean and std\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWxGwVPBBOk4"
   },
   "outputs": [],
   "source": [
    "# Define the test function\n",
    "def test(model, test_dataset_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load test dataset\n",
    "    test_dataset = TestDataset(test_dataset_path)\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for img, label in test_dataset:\n",
    "        img = img.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        output = model(img).item()  # Forward pass\n",
    "\n",
    "        pred = 1 if output > 0.5 else 0  # Sigmoid threshold\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmEkZWU7BUJ5"
   },
   "outputs": [],
   "source": [
    "# Replace these paths before running the test\n",
    "test_dataset_path = ''  # Replace with the path to the test dataset folder\n",
    "model_path = 'DenseNet121_model.pth'  # Replace with the path to the saved model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqWfkUWsBUd9"
   },
   "outputs": [],
   "source": [
    "# Load the trained DenseNet121 model\n",
    "model = build_densenet_model()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbJpmzhDBWb-"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = test(model, test_dataset_path)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
