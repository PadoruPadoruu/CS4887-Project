{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFwqVBE_3CGZ"
   },
   "source": [
    "Member 1 : KEUNG Yat LONG\n",
    "SID : 5714 6792\n",
    "\n",
    "Member 2 : Wong Pedro\n",
    "SID : 56751109\n",
    "\n",
    "Member 3 : KO Ka Chun\n",
    "SID : 56744470"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85FGcnIy3w58"
   },
   "source": [
    "#Background\n",
    "___\n",
    "- Image generation techniques have existed for decades.\n",
    "- Recent deep learning advances (GANs, diffusion models) have boosted photorealism in AI-generated content (AIGC).\n",
    "- While these advancements have entertainment value, they also pose risks of weaponization.\n",
    "- Detecting AIGC is now a critical issue and a prominent research focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MebXnVvg6bP7"
   },
   "source": [
    "#Basic Information\n",
    "---\n",
    "- **Main task**: Binary classification (detect whether an image is AI-generated or not).\n",
    "- **Input**: RGB images.\n",
    "- **Output**: Binary label indicating if the image is AI-generated.\n",
    "- **Training set**: 45,000 images.\n",
    "- **Validation set**: 5,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSQscqPt5w1n"
   },
   "source": [
    "#Dataset Exploration\n",
    "---\n",
    "- Dataset includes both photographic and AI-generated images.\n",
    "- Photographic images are sourced from ImageNet with varying sizes.\n",
    "- AI-generated images are 512 × 512 × 3, created using Stable Diffusion v1.4, trained on the LAION dataset.\n",
    "- Photographic and AI-generated images have similar semantic content to avoid content bias.\n",
    "- Only binary labels are available for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO8GCV7B8nJw"
   },
   "source": [
    "##Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qK58bk2E9-3N",
    "outputId": "a3a32e8f-a793-43ca-a946-e9ddf9eba8d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2seNI4j2i3w",
    "outputId": "4edb05c7-2d67-46e6-fcbd-1d915d7c78e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted to AIGC_Dataset\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_file_path = '/content/drive/MyDrive/CS4487/CS4487 Project/AIGC-Detection-Dataset.zip'\n",
    "\n",
    "# Create a directory to extract the dataset\n",
    "output_dir = 'AIGC_Dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_dir)\n",
    "\n",
    "print(f'Dataset extracted to {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtO_emP78u3W"
   },
   "source": [
    "##Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhdG3qhh8zFc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgW2yfvkBJKB"
   },
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HwOAxuXBKvm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9b0c-9kBMW_"
   },
   "outputs": [],
   "source": [
    "# Define a custom dataset loader for binary classification\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        real_dir = os.path.join(data_dir, '0_real')\n",
    "        fake_dir = os.path.join(data_dir, '1_fake')\n",
    "\n",
    "        # Load file paths and labels\n",
    "        self.image_paths = [os.path.join(real_dir, f) for f in os.listdir(real_dir)] + \\\n",
    "                           [os.path.join(fake_dir, f) for f in os.listdir(fake_dir)]\n",
    "        self.labels = [0] * len(os.listdir(real_dir)) + [1] * len(os.listdir(fake_dir))\n",
    "\n",
    "        # Image transformations\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4778, 0.4559, 0.4175], [0.2794, 0.2739, 0.2902])  # Normalize using ImageNet's mean and std\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWxGwVPBBOk4"
   },
   "outputs": [],
   "source": [
    "# Define the test function\n",
    "def test(model, test_dataset_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load test dataset\n",
    "    test_dataset = TestDataset(test_dataset_path)\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for img, label in test_dataset:\n",
    "        img = img.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        output = model(img).item()  # Forward pass\n",
    "\n",
    "        pred = 1 if output > 0.5 else 0  # Sigmoid threshold\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmEkZWU7BUJ5"
   },
   "outputs": [],
   "source": [
    "# Replace these paths before running the test\n",
    "test_dataset_path = ''  # Replace with the path to the test dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define DenseNet model\n",
    "def build_densenet_model():\n",
    "    base_model = models.densenet121(weights=None)  # Initialize without pretrained weights\n",
    "    num_features = base_model.classifier.in_features\n",
    "    base_model.classifier = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.8),\n",
    "        nn.Linear(512, 1),\n",
    "    )\n",
    "    return base_model\n",
    "\n",
    "# Define Swin model\n",
    "def build_swin_model():\n",
    "    swin_model = models.swin_t(weights=None)  # Initialize without pretrained weights\n",
    "    swin_model.head = nn.Linear(swin_model.head.in_features, 1)  # Binary classification\n",
    "    return swin_model\n",
    "\n",
    "# Define the Ensemble Model\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, densenet, swin, classifier):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.densenet = densenet\n",
    "        self.swin = swin\n",
    "        self.classifier = classifier\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # For DenseNet pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        # DenseNet features\n",
    "        densenet_features = self.densenet.features(x)\n",
    "        densenet_pooled = self.global_avg_pool(densenet_features)\n",
    "        densenet_flattened = torch.flatten(densenet_pooled, start_dim=1)\n",
    "\n",
    "        # Swin features\n",
    "        swin_features = self.swin(x).squeeze().unsqueeze(1)\n",
    "\n",
    "        # Combine features\n",
    "        combined_features = torch.cat([densenet_flattened, swin_features], dim=1)\n",
    "\n",
    "        # Classifier\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n",
    "\n",
    "# Initialize the models and classifier\n",
    "densenet_model = build_densenet_model()\n",
    "swin_model = build_swin_model()\n",
    "\n",
    "ensemble_classifier = nn.Sequential(\n",
    "    nn.Linear(1025, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(512, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ensemble Model\n",
    "ensemble_model = EnsembleModel(densenet_model, swin_model, ensemble_classifier).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved state dict\n",
    "ensemble_model.load_state_dict(torch.load(\"ensemble_model.pth\"))\n",
    "ensemble_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbJpmzhDBWb-"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = test(ensemble_model, test_dataset_path)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
